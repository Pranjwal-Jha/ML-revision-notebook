{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "id": "b6c56c940ab55394"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "array = np.arange(24)\n",
    "array2 = array.reshape(3,2,4)\n",
    "print(array2)"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#print(array2[[1],:,1:3])\n",
    "#print(array2[[2],[1],:])\n",
    "print(array2.min(axis=0))"
   ],
   "id": "d000d14231465cc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "ad3ffbcaffb8cf7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cars = pd.read_csv('cars.csv')\n",
    "#cars.describe()\n",
    "#cars.info()\n",
    "cars.head(5)"
   ],
   "id": "a813afc41b7f6b77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "afe9dd6136144131"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cars[['brand','owner']].head(5)",
   "id": "ec858bf75ed0ebb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_cars(city,owner):\n",
    "    mask1 = cars['brand']==city\n",
    "    mask2 = cars['owner']==owner\n",
    "    return cars[mask1 & mask2].shape[0]\n",
    "print(get_cars(\"Skoda\",\"First Owner\"))"
   ],
   "id": "2c9ba747399042c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(cars['owner'].value_counts())\n",
    "t_car = cars[cars['owner']==\"Fourth & Above Owner\"]\n",
    "print(t_car['brand'].value_counts())"
   ],
   "id": "84dbd37355e200ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "cars['brand'].value_counts().plot(kind='bar',figsize=(10,5))"
   ],
   "id": "645e7e7c3e2aaf28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "brand = cars.groupby('brand')",
   "id": "27e5354e373e7179",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "brand.size().head(1)",
   "id": "25f9b186e86f4901",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "brand['km_driven'].mean().head(1)",
   "id": "60cc32db462ec630",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "brand.get_group('BMW').head(1)",
   "id": "797e4a52862cfbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cars.pivot_table(index='brand',columns = 'owner',values='km_driven',aggfunc='mean')\n",
    "cars.head(1)"
   ],
   "id": "7423eebd5b6c196a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(cars['selling_price'])"
   ],
   "id": "5cc5ac772705caf9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "##sns.boxplot(cars['selling_price'])\n",
    "cars[cars['selling_price']==cars['selling_price'].max()]"
   ],
   "id": "ffbf8553e831ca68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "titanic = pd.read_csv('titanic_toy.csv')\n",
    "titanic.head()"
   ],
   "id": "3d6572fb7dfa3388",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(titanic.drop(('Survived'),axis=1),titanic['Survived'], test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n"
   ],
   "id": "54976c853d86e63b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ],
   "id": "8831e04420f11272",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_test_scaled = pd.DataFrame(x_test_scaled,columns=x_test.columns)\n",
    "x_test_scaled.head(10)"
   ],
   "id": "b228c0fd2541ef48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "titanic.head()",
   "id": "852b37e32df0428d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming Titanic dataset is loaded in a DataFrame called 'titanic'\n",
    "sns.histplot(titanic['Age'], kde=True)  # For Age\n",
    "plt.title('Age Distribution')\n",
    "plt.show()\n"
   ],
   "id": "c4dfe7650f465828",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ENCODING CATEGORICAL DATA\n",
    "- nominal encoding -> this is when there's no relation between categories\n",
    "- ordinal encoding -> when relationship between categories e.x. excellent, good\n",
    "- label encoding -> ordinal encoding but specifically made for output\n",
    "\n",
    "### ORDINAL ENCODING\n",
    "- if we dont want to run some columns then we can slice the data and then merge later\n",
    "- e.x. final_data = pd.concat([encoded_df, data['col3']], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "b5a171ab121454b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "oe = OrdinalEncoder(categories=[['Poor','Average','Good'],['School','UG','PG']])\n",
    "x_train = oe.fit_transform(x_train)\n",
    "x_test = oe.transform(x_test)\n",
    "le = LabelEncoder()\n",
    "# fit on y_train and y_test this does not need any input"
   ],
   "id": "87a0901c770dd1df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ONE HOT ENCODING\n",
    "- pandas one hot encoding\n",
    "- scikit learn one hot encoding\n",
    "- k-1 one hot encoding\n",
    "- one hot encoding with top categories -> when we too many categories\n",
    "\n",
    "#### drop = 'first'\n",
    "- this is done to avoid redundancy\n",
    "- blue, green, red ball encoding problem\n",
    "- avoid this for tree based models like xgboost, random forest, decision forest etc\n",
    "\n"
   ],
   "id": "fa8db1dd0b76f873"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "x_train_new = ohe.fit_transform(x_train[['fuel','owner']])\n",
    "x_test_new = ohe.transform(x_test[['fuel','owner']])"
   ],
   "id": "f67253c611ea26d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## COLUMN TRANSFORMER\n",
    "- tnf1 etc are just name give to find the columns if we want to see the pipelines\n",
    "\n"
   ],
   "id": "9f01dc75949bac3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer # to fill in the missing values\n",
    "transformer = ColumnTransformer(transformers=[\n",
    "    ('tnf1',SimpleImputer(),['fever']),\n",
    "    ('tnf2',OrdinalEncoder(categories=[['Mild','Strong']]),['cough']),\n",
    "    ('tnf3',OneHotEncoder(sparse=False,drop='first'),['gender','city'])\n",
    "],remainder='passthrough')\n",
    "transformer.fit_transform(x_train)\n",
    "transformer.transform(x_test)"
   ],
   "id": "512cb157ace506b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PIPELINES\n",
    "- multiple steps chained together\n",
    "- missing values impute -> encoding -> scaling -> feature selection -> decision tree model\n",
    "- multiple columns transformers -> finally added to one pipeline\n",
    "#### Pipeline VS make_pipeline\n",
    "- pipelines requires naming of steps, make_pipeline does not"
   ],
   "id": "8c588fdf6f09a92f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pipe = Pipeline([\n",
    "    ('trf1',trf1),\n",
    "    ('trf2',trf2),\n",
    "    ('trf3',trf3),\n",
    "    ('trf4',trf4),\n",
    "    ('trf5',trf5)\n",
    "])\n",
    "# where trf1 etc. are all column transformers, feature selection, model training\n",
    "y_pred = pipe.predict(x_test)"
   ],
   "id": "8e83584ec33e3301"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## FUNCTION TRANSFORMERS\n",
    "- implemented on columns to make data normal -> algorithm performance better\n",
    "- log transform -> cannot be applied on -ve values\n",
    "- reciprocal\n",
    "- power\n",
    "### POWER TRANSFORMERS\n",
    "- Box-cox -> only +ve\n",
    "- y(lambda) =\n",
    "\\begin{cases}\n",
    "\\frac{y^\\lambda - 1}{\\lambda}, & \\text{if } \\lambda \\neq 0 \\\\\n",
    "\\ln(y), & \\text{if } \\lambda = 0\n",
    "\\end{cases}\n",
    "\n",
    "- yeojohsnon -> modification of boxcox, applied to -ve also\n",
    "- y(lambda) = \\begin{cases}\n",
    "\\frac{(y + 1)^\\lambda - 1}{\\lambda}, & \\text{if } \\lambda \\neq 0 \\text{ and } y \\geq 0 \\\\\n",
    "\\ln(y + 1), & \\text{if } \\lambda = 0 \\text{ and } y \\geq 0 \\\\\n",
    "\\frac{-( (-y + 1)^{2 - \\lambda} - 1 )}{2 - \\lambda}, & \\text{if } \\lambda \\neq 2 \\text{ and } y < 0 \\\\\n",
    "-\\ln(-y + 1), & \\text{if } \\lambda = 2 \\text{ and } y < 0\n",
    "\\end{cases}\n",
    "\n",
    "\n",
    "#### CHECK DATA\n",
    "- use QQ plot\n",
    "- if normally distributed, all points on the line of QQ plot\n",
    "- if skewed right -> line going above ideal at end\n",
    "- if skewed left -> line going below ideal at beginning"
   ],
   "id": "c531caa39dc684cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "trf=FunctionTransformer(np.log1p) # logtransform we just log the values of column\n",
    "# fit_transform this on x_train and transform x_test\n",
    "# np.log1p adds 1 to value and then logs it, hence doesn't gives error if value - 0\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "pt = PowerTransformer() # by default works on yeo johnson just need to fit and transform"
   ],
   "id": "c9d4d61815c337d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# BINNING\n",
    "- grouping values in range\n",
    "- helps in handling outliers\n",
    "## UNSUPERVISED BINNING\n",
    "### EQUAL WIDTH\n",
    "- no change in the spread of data\n",
    "- handles outliers\n",
    "\n",
    "### EQUAL FREQUENCY\n",
    "- handle outliers\n",
    "- make data more uniform\n",
    "\n",
    "### K BINNING"
   ],
   "id": "36591f7c3c1f167"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "kbin_age = KBinsDiscretizer(n_bins=15,encode='ordinal',strategy='quantile')\n",
    "# add some other binner on other column and make a columntransformer"
   ],
   "id": "8ecc8720260aa135"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- see how to deal with mixed data, that is when data contains letter and number e.x. B53 PRANJWAL4798 etc\n",
    "- see how to work with dates, python can convert columns to date type. written in notebook\n",
    "\n",
    "## HANDLING MISSING DATA\n",
    "### 1) REMOVING THE ROWS\n",
    "- when data missing at random\n",
    "- data missing <5% of actual data\n",
    "### 2) IMPUTING THEM (FILLING)\n",
    "- univariate(numerical, categorical)\n",
    "- multivariate(KNN, iterative imputer)\n",
    "\n",
    "#### Handling missing numerical data\n",
    "- normal distribution -> mean/median\n",
    "- skewed dis -> median\n",
    "- randomly  -> useful with linear regression not with decision tree\n",
    "\n",
    "#### Handling categorical missing data\n",
    "- most frequent\n",
    "- new missing\n",
    "- random"
   ],
   "id": "b23c2360c46a2b2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# df.isnull().mean()*100\n",
    "from sklearn.impute import SimpleImputer\n",
    "sip = SimpleImputer(strategy='median') # default is mean\n",
    "# most_frequent etc\n",
    "\n",
    "#categorical ->\n",
    "df['categorical_col'].fillname('TA', inplace=True)\n",
    "#or use a simple imputer with strategy = most_frequent"
   ],
   "id": "ebadfe11e966243b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## KNNImputer\n",
    "- more accurate, but has more calculations\n",
    "- missing values imputed from mean from nearest neighbour (distance) found in training set"
   ],
   "id": "c33708aed74541de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T17:58:31.661183Z",
     "start_time": "2024-12-25T17:58:31.491135Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.impute import KNNImputer",
   "id": "3f2577310e0e751d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## MICE(multivariate imputation by chained equations)\n",
    "- use when missing at random\n",
    "- do not use when not missing at random\n",
    "- iterative imputation\n",
    "- check obsidian note"
   ],
   "id": "77dcd01a140781bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T18:14:14.427811Z",
     "start_time": "2024-12-25T18:14:14.420663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#from sklearn.impute import IterativeImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "#for mice"
   ],
   "id": "c4fc41026d7ce6c2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## OUTLIER DETECTION\n",
    "- trimming (removing)\n",
    "- capping (limiting)\n",
    "- assuming them as missing values\n",
    "- discretization\n",
    "\n",
    "### For detecting outliers\n",
    "- z score treatment -> works on col with almost normal distribution; z_score>3 -> outlier\n",
    "- IQR based filtering -> boxplot Q1-1.5 * IQR , Q3+1.5 * IQR\n",
    "- percentile -> 1 to 99 percentile boundary\n",
    "- wiscorization\n"
   ],
   "id": "6614b7ea32ee877e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#we can do capping using the np.where statement where we pass 3 parameters (condition,if true,if false)\n",
    "# capping ->\n",
    "df['cgpa'] = np.where(np['cgpa']>max_cgpa, max_cgpa,np.where(df['cgpa']<min_cgpa,min_cgpa,df['cgpa']))\n",
    "#if greater than max_limit -> set to max_limit\n",
    "#otherwise set to min_limit and if not keep as it is (for normal values)"
   ],
   "id": "be0961b9de20e53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "67538fc9fba461a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "cc3a24fcd07e30d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "31ee445553ba1064"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
